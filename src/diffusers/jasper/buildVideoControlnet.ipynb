{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal unet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wisley/miniconda3/envs/wsl_diffusers/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/wisley/miniconda3/envs/wsl_diffusers/lib/python3.9/site-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import debugpy\n",
    "from typing import Optional, Tuple, Union\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from diffusers.models.unets import UNetSpatioTemporalConditionModel\n",
    "from diffusers import StableVideoDiffusionPipeline\n",
    "from diffusers.utils import load_image, export_to_video\n",
    "from diffusers.utils.torch_utils import is_compiled_module, randn_tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from diffusers.configuration_utils import ConfigMixin, register_to_config\n",
    "from diffusers.loaders import UNet2DConditionLoadersMixin\n",
    "from diffusers.utils import BaseOutput, logging\n",
    "from diffusers.models.attention_processor import CROSS_ATTENTION_PROCESSORS, AttentionProcessor, AttnProcessor\n",
    "from diffusers.models.embeddings import TimestepEmbedding, Timesteps\n",
    "from diffusers.models.modeling_utils import ModelMixin\n",
    "from diffusers.models.unets.unet_3d_blocks import UNetMidBlockSpatioTemporal, get_down_block, get_up_block\n",
    "from diffusers.models.unets import UNetSpatioTemporalConditionModel\n",
    "\n",
    "\n",
    "from types import MethodType\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'num_frames': 2} are not expected by StableVideoDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|██████████| 5/5 [00:00<00:00, 10.15it/s]\n"
     ]
    }
   ],
   "source": [
    "pipe = StableVideoDiffusionPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-video-diffusion-img2vid-xt\", torch_dtype=torch.float16, variant=\"fp16\", num_frames = 2\n",
    ")\n",
    "pipe.enable_model_cpu_offload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrozenDict([('vae', ('diffusers', 'AutoencoderKLTemporalDecoder')), ('image_encoder', ('transformers', 'CLIPVisionModelWithProjection')), ('unet', ('diffusers', 'UNetSpatioTemporalConditionModel')), ('scheduler', ('diffusers', 'EulerDiscreteScheduler')), ('feature_extractor', ('transformers', 'CLIPImageProcessor')), ('_name_or_path', 'stabilityai/stable-video-diffusion-img2vid-xt')])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_config = pipe.config\n",
    "print(pipe_config)\n",
    "unet_weights = pipe.unet.state_dict()\n",
    "my_net = UNetSpatioTemporalConditionModel()\n",
    "my_net.load_state_dict(unet_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent model input dtype: torch.float16\n",
      "Hidden image embeddings dtype: torch.float16\n",
      "torch.Size([2, 1, 8, 64, 64])\n",
      "torch.Size([2, 1, 1024])\n",
      "torch.Size([2, 3])\n",
      "Latent model input is on: cuda:0\n",
      "Hidden image embeddings are on: cuda:0\n",
      "Added time IDs are on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "def prepare_latents(\n",
    "    batch_size,\n",
    "    num_frames,\n",
    "    num_channels_latents,\n",
    "    height,\n",
    "    width,\n",
    "    dtype,\n",
    "    device,\n",
    "    generator,\n",
    "    latents=None,\n",
    "):\n",
    "    shape = (\n",
    "        batch_size,\n",
    "        num_frames,\n",
    "        num_channels_latents // 2,\n",
    "        height // 1,\n",
    "        width // 1,\n",
    "    )\n",
    "    if isinstance(generator, list) and len(generator) != batch_size:\n",
    "        raise ValueError(\n",
    "            f\"You have passed a list of generators of length {len(generator)}, but requested an effective batch\"\n",
    "            f\" size of {batch_size}. Make sure the batch size matches the length of the generators.\"\n",
    "        )\n",
    "\n",
    "    if latents is None:\n",
    "        latents = randn_tensor(shape, generator=generator, device=device, dtype=dtype)\n",
    "    else:\n",
    "        latents = latents.to(device)\n",
    "\n",
    "    # scale the initial noise by the standard deviation required by the scheduler\n",
    "    latents = latents * 0.2\n",
    "    return latents\n",
    "\n",
    "def pseudo_image_embeddings( shape, generator, device, dtype, do_classifier_free_guidance = True ):\n",
    "    image_embeddings = randn_tensor(shape, generator=generator, device= device, dtype=dtype)\n",
    "\n",
    "    if do_classifier_free_guidance:\n",
    "        negative_image_embeddings = torch.zeros_like(image_embeddings)\n",
    "\n",
    "        # For classifier free guidance, we need to do two forward passes.\n",
    "        # Here we concatenate the unconditional and text embeddings into a single batch\n",
    "        # to avoid doing two forward passes\n",
    "        return torch.cat([negative_image_embeddings, image_embeddings])\n",
    "\n",
    "def get_add_time_ids(\n",
    "  fps = 7,\n",
    "  motion_bucket_id = 127,\n",
    "  noise_aug_strength = 0.02,\n",
    "  dtype = torch.float32,\n",
    "  batch_size = 1,\n",
    "  num_videos_per_prompt = 1,\n",
    "  do_classifier_free_guidance = True,\n",
    "):\n",
    "  add_time_ids = [fps, motion_bucket_id, noise_aug_strength]\n",
    "\n",
    "  add_time_ids = torch.tensor([add_time_ids], dtype=dtype)\n",
    "  add_time_ids = add_time_ids.repeat(batch_size * num_videos_per_prompt, 1)\n",
    "\n",
    "  if do_classifier_free_guidance:\n",
    "      add_time_ids = torch.cat([add_time_ids, add_time_ids])\n",
    "\n",
    "  return add_time_ids\n",
    "\n",
    "dtype = torch.float16\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "generator = torch.Generator().manual_seed(42)  # For reproducibility\n",
    "\n",
    "# Generate original latents with specified dtype\n",
    "my_latents = prepare_latents(1, 1, 8, 64, 64, dtype, device, generator)\n",
    "\n",
    "# Apply classifier-free guidance by duplicating the latents and ensuring the correct dtype\n",
    "latent_model_input = torch.cat([my_latents] * 2)  # Inherits dtype from my_latents\n",
    "\n",
    "# Create pseudo image latents by cloning the original latents\n",
    "pseudo_image_latents = latent_model_input.clone()  # Inherits dtype\n",
    "\n",
    "# Concatenate pseudo image latents over the channels dimension, ensuring matching dtype\n",
    "latent_model_input = torch.cat([latent_model_input, pseudo_image_latents], dim=2)\n",
    "\n",
    "\n",
    "# Create the fake image embeddings with the specified dtype\n",
    "hidden_image_embeddings = pseudo_image_embeddings((1, 1, 1024), generator, device, dtype)\n",
    "\n",
    "added_time_ids = get_add_time_ids(dtype=dtype).to(device)\n",
    "\n",
    "# Verify the dtype of both tensors\n",
    "print(f\"Latent model input dtype: {latent_model_input.dtype}\")\n",
    "print(f\"Hidden image embeddings dtype: {hidden_image_embeddings.dtype}\")\n",
    "\n",
    "print(latent_model_input.shape)\n",
    "print(hidden_image_embeddings.shape)\n",
    "print(added_time_ids.shape)\n",
    "\n",
    "# Print on which model they are\n",
    "print(f\"Latent model input is on: {latent_model_input.device}\")\n",
    "print(f\"Hidden image embeddings are on: {hidden_image_embeddings.device}\")\n",
    "# Assuming added_time_ids is also a tensor; replace this with the actual tensor variable if different\n",
    "print(f\"Added time IDs are on: {added_time_ids.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNetSpatioTemporalConditionModel(\n",
       "  (conv_in): Conv2d(8, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (time_proj): Timesteps()\n",
       "  (time_embedding): TimestepEmbedding(\n",
       "    (linear_1): LoRACompatibleLinear(in_features=320, out_features=1280, bias=True)\n",
       "    (act): SiLU()\n",
       "    (linear_2): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "  )\n",
       "  (add_time_proj): Timesteps()\n",
       "  (add_embedding): TimestepEmbedding(\n",
       "    (linear_1): LoRACompatibleLinear(in_features=768, out_features=1280, bias=True)\n",
       "    (act): SiLU()\n",
       "    (linear_2): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "  )\n",
       "  (down_blocks): ModuleList(\n",
       "    (0): CrossAttnDownBlockSpatioTemporal(\n",
       "      (attentions): ModuleList(\n",
       "        (0-1): 2 x TransformerSpatioTemporalModel(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=1024, out_features=320, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=1024, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (temporal_transformer_blocks): ModuleList(\n",
       "            (0): TemporalBasicTransformerBlock(\n",
       "              (norm_in): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff_in): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=1024, out_features=320, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=1024, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (time_pos_embed): TimestepEmbedding(\n",
       "            (linear_1): LoRACompatibleLinear(in_features=320, out_features=1280, bias=True)\n",
       "            (act): SiLU()\n",
       "            (linear_2): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "          )\n",
       "          (time_proj): Timesteps()\n",
       "          (time_mixer): AlphaBlender()\n",
       "          (proj_out): Linear(in_features=320, out_features=320, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x SpatioTemporalResBlock(\n",
       "          (spatial_res_block): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "            (conv1): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "            (norm2): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "          (temporal_res_block): TemporalResnetBlock(\n",
       "            (norm1): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "            (conv1): Conv3d(320, 320, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (norm2): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv3d(320, 320, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): CrossAttnDownBlockSpatioTemporal(\n",
       "      (attentions): ModuleList(\n",
       "        (0-1): 2 x TransformerSpatioTemporalModel(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Linear(in_features=640, out_features=640, bias=True)\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (temporal_transformer_blocks): ModuleList(\n",
       "            (0): TemporalBasicTransformerBlock(\n",
       "              (norm_in): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff_in): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (time_pos_embed): TimestepEmbedding(\n",
       "            (linear_1): LoRACompatibleLinear(in_features=640, out_features=2560, bias=True)\n",
       "            (act): SiLU()\n",
       "            (linear_2): LoRACompatibleLinear(in_features=2560, out_features=640, bias=True)\n",
       "          )\n",
       "          (time_proj): Timesteps()\n",
       "          (time_mixer): AlphaBlender()\n",
       "          (proj_out): Linear(in_features=640, out_features=640, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): SpatioTemporalResBlock(\n",
       "          (spatial_res_block): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "            (conv1): LoRACompatibleConv(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n",
       "            (norm2): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (temporal_res_block): TemporalResnetBlock(\n",
       "            (norm1): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (conv1): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            (norm2): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "        (1): SpatioTemporalResBlock(\n",
       "          (spatial_res_block): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (conv1): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n",
       "            (norm2): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "          (temporal_res_block): TemporalResnetBlock(\n",
       "            (norm1): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (conv1): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            (norm2): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): CrossAttnDownBlockSpatioTemporal(\n",
       "      (attentions): ModuleList(\n",
       "        (0-1): 2 x TransformerSpatioTemporalModel(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (temporal_transformer_blocks): ModuleList(\n",
       "            (0): TemporalBasicTransformerBlock(\n",
       "              (norm_in): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff_in): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (time_pos_embed): TimestepEmbedding(\n",
       "            (linear_1): LoRACompatibleLinear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): SiLU()\n",
       "            (linear_2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n",
       "          )\n",
       "          (time_proj): Timesteps()\n",
       "          (time_mixer): AlphaBlender()\n",
       "          (proj_out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): SpatioTemporalResBlock(\n",
       "          (spatial_res_block): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (conv1): LoRACompatibleConv(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "            (norm2): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (temporal_res_block): TemporalResnetBlock(\n",
       "            (norm1): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (conv1): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (norm2): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "        (1): SpatioTemporalResBlock(\n",
       "          (spatial_res_block): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (conv1): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "            (norm2): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "          (temporal_res_block): TemporalResnetBlock(\n",
       "            (norm1): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (conv1): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (norm2): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): DownBlockSpatioTemporal(\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x SpatioTemporalResBlock(\n",
       "          (spatial_res_block): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "            (conv1): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "            (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "          (temporal_res_block): TemporalResnetBlock(\n",
       "            (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "            (conv1): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_blocks): ModuleList(\n",
       "    (0): UpBlockSpatioTemporal(\n",
       "      (resnets): ModuleList(\n",
       "        (0-2): 3 x SpatioTemporalResBlock(\n",
       "          (spatial_res_block): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 2560, eps=1e-06, affine=True)\n",
       "            (conv1): LoRACompatibleConv(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "            (norm2): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (temporal_res_block): TemporalResnetBlock(\n",
       "            (norm1): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (conv1): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (norm2): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "      )\n",
       "      (upsamplers): ModuleList(\n",
       "        (0): Upsample2D(\n",
       "          (conv): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): CrossAttnUpBlockSpatioTemporal(\n",
       "      (attentions): ModuleList(\n",
       "        (0-2): 3 x TransformerSpatioTemporalModel(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (temporal_transformer_blocks): ModuleList(\n",
       "            (0): TemporalBasicTransformerBlock(\n",
       "              (norm_in): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff_in): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (time_pos_embed): TimestepEmbedding(\n",
       "            (linear_1): LoRACompatibleLinear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): SiLU()\n",
       "            (linear_2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n",
       "          )\n",
       "          (time_proj): Timesteps()\n",
       "          (time_mixer): AlphaBlender()\n",
       "          (proj_out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x SpatioTemporalResBlock(\n",
       "          (spatial_res_block): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 2560, eps=1e-06, affine=True)\n",
       "            (conv1): LoRACompatibleConv(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "            (norm2): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (temporal_res_block): TemporalResnetBlock(\n",
       "            (norm1): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (conv1): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (norm2): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "        (2): SpatioTemporalResBlock(\n",
       "          (spatial_res_block): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 1920, eps=1e-06, affine=True)\n",
       "            (conv1): LoRACompatibleConv(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "            (norm2): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (temporal_res_block): TemporalResnetBlock(\n",
       "            (norm1): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (conv1): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (norm2): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "      )\n",
       "      (upsamplers): ModuleList(\n",
       "        (0): Upsample2D(\n",
       "          (conv): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): CrossAttnUpBlockSpatioTemporal(\n",
       "      (attentions): ModuleList(\n",
       "        (0-2): 3 x TransformerSpatioTemporalModel(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Linear(in_features=640, out_features=640, bias=True)\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (temporal_transformer_blocks): ModuleList(\n",
       "            (0): TemporalBasicTransformerBlock(\n",
       "              (norm_in): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff_in): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (time_pos_embed): TimestepEmbedding(\n",
       "            (linear_1): LoRACompatibleLinear(in_features=640, out_features=2560, bias=True)\n",
       "            (act): SiLU()\n",
       "            (linear_2): LoRACompatibleLinear(in_features=2560, out_features=640, bias=True)\n",
       "          )\n",
       "          (time_proj): Timesteps()\n",
       "          (time_mixer): AlphaBlender()\n",
       "          (proj_out): Linear(in_features=640, out_features=640, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): SpatioTemporalResBlock(\n",
       "          (spatial_res_block): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 1920, eps=1e-06, affine=True)\n",
       "            (conv1): LoRACompatibleConv(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n",
       "            (norm2): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (temporal_res_block): TemporalResnetBlock(\n",
       "            (norm1): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (conv1): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            (norm2): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "        (1): SpatioTemporalResBlock(\n",
       "          (spatial_res_block): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (conv1): LoRACompatibleConv(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n",
       "            (norm2): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (temporal_res_block): TemporalResnetBlock(\n",
       "            (norm1): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (conv1): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            (norm2): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "        (2): SpatioTemporalResBlock(\n",
       "          (spatial_res_block): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 960, eps=1e-06, affine=True)\n",
       "            (conv1): LoRACompatibleConv(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n",
       "            (norm2): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (temporal_res_block): TemporalResnetBlock(\n",
       "            (norm1): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (conv1): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            (norm2): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "      )\n",
       "      (upsamplers): ModuleList(\n",
       "        (0): Upsample2D(\n",
       "          (conv): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): CrossAttnUpBlockSpatioTemporal(\n",
       "      (attentions): ModuleList(\n",
       "        (0-2): 3 x TransformerSpatioTemporalModel(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=1024, out_features=320, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=1024, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (temporal_transformer_blocks): ModuleList(\n",
       "            (0): TemporalBasicTransformerBlock(\n",
       "              (norm_in): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff_in): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=1024, out_features=320, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=1024, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (time_pos_embed): TimestepEmbedding(\n",
       "            (linear_1): LoRACompatibleLinear(in_features=320, out_features=1280, bias=True)\n",
       "            (act): SiLU()\n",
       "            (linear_2): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "          )\n",
       "          (time_proj): Timesteps()\n",
       "          (time_mixer): AlphaBlender()\n",
       "          (proj_out): Linear(in_features=320, out_features=320, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): SpatioTemporalResBlock(\n",
       "          (spatial_res_block): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 960, eps=1e-06, affine=True)\n",
       "            (conv1): LoRACompatibleConv(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "            (norm2): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (temporal_res_block): TemporalResnetBlock(\n",
       "            (norm1): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "            (conv1): Conv3d(320, 320, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (norm2): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv3d(320, 320, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "        (1-2): 2 x SpatioTemporalResBlock(\n",
       "          (spatial_res_block): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (conv1): LoRACompatibleConv(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "            (norm2): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (temporal_res_block): TemporalResnetBlock(\n",
       "            (norm1): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "            (conv1): Conv3d(320, 320, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (norm2): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv3d(320, 320, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mid_block): UNetMidBlockSpatioTemporal(\n",
       "    (attentions): ModuleList(\n",
       "      (0): TransformerSpatioTemporalModel(\n",
       "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "        (proj_in): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn1): Attention(\n",
       "              (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_v): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_out): ModuleList(\n",
       "                (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn2): Attention(\n",
       "              (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): LoRACompatibleLinear(in_features=1024, out_features=1280, bias=False)\n",
       "              (to_v): LoRACompatibleLinear(in_features=1024, out_features=1280, bias=False)\n",
       "              (to_out): ModuleList(\n",
       "                (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (ff): FeedForward(\n",
       "              (net): ModuleList(\n",
       "                (0): GEGLU(\n",
       "                  (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (temporal_transformer_blocks): ModuleList(\n",
       "          (0): TemporalBasicTransformerBlock(\n",
       "            (norm_in): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (ff_in): FeedForward(\n",
       "              (net): ModuleList(\n",
       "                (0): GEGLU(\n",
       "                  (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn1): Attention(\n",
       "              (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_v): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_out): ModuleList(\n",
       "                (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn2): Attention(\n",
       "              (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): LoRACompatibleLinear(in_features=1024, out_features=1280, bias=False)\n",
       "              (to_v): LoRACompatibleLinear(in_features=1024, out_features=1280, bias=False)\n",
       "              (to_out): ModuleList(\n",
       "                (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (ff): FeedForward(\n",
       "              (net): ModuleList(\n",
       "                (0): GEGLU(\n",
       "                  (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (time_pos_embed): TimestepEmbedding(\n",
       "          (linear_1): LoRACompatibleLinear(in_features=1280, out_features=5120, bias=True)\n",
       "          (act): SiLU()\n",
       "          (linear_2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "        (time_proj): Timesteps()\n",
       "        (time_mixer): AlphaBlender()\n",
       "        (proj_out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (resnets): ModuleList(\n",
       "      (0-1): 2 x SpatioTemporalResBlock(\n",
       "        (spatial_res_block): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (conv1): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "        (temporal_res_block): TemporalResnetBlock(\n",
       "          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (conv1): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "        (time_mixer): AlphaBlender()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_norm_out): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "  (conv_act): SiLU()\n",
       "  (conv_out): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_net = my_net.half()\n",
    "my_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the batch size 2\n",
      "Res samples shape unet: torch.Size([2, 320, 64, 64])\n",
      "Res samples shape unet: torch.Size([2, 640, 32, 32])\n",
      "Res samples shape unet: torch.Size([2, 1280, 16, 16])\n",
      "Res samples shape unet: torch.Size([2, 1280, 8, 8])\n",
      "Down block res samples shape uuuuuuuu: torch.Size([2, 320, 64, 64])\n",
      "Down block res samples shape uuuuuuuu: torch.Size([2, 320, 64, 64])\n",
      "Down block res samples shape uuuuuuuu: torch.Size([2, 320, 64, 64])\n",
      "Down block res samples shape uuuuuuuu: torch.Size([2, 320, 32, 32])\n",
      "Down block res samples shape uuuuuuuu: torch.Size([2, 640, 32, 32])\n",
      "Down block res samples shape uuuuuuuu: torch.Size([2, 640, 32, 32])\n",
      "Down block res samples shape uuuuuuuu: torch.Size([2, 640, 16, 16])\n",
      "Down block res samples shape uuuuuuuu: torch.Size([2, 1280, 16, 16])\n",
      "Down block res samples shape uuuuuuuu: torch.Size([2, 1280, 16, 16])\n",
      "Down block res samples shape uuuuuuuu: torch.Size([2, 1280, 8, 8])\n",
      "Down block res samples shape uuuuuuuu: torch.Size([2, 1280, 8, 8])\n",
      "Down block res samples shape uuuuuuuu: torch.Size([2, 1280, 8, 8])\n",
      "This is the iteration 0\n",
      "This is the iteration 1\n",
      "This is the iteration 2\n",
      "This is the iteration 3\n",
      "torch.Size([2, 1, 4, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    noise_pred = my_net.forward(\n",
    "        latent_model_input.to(dtype=dtype),\n",
    "        torch.tensor(1).to(dtype=dtype, device=device),\n",
    "        encoder_hidden_states=hidden_image_embeddings.to(dtype=dtype),\n",
    "        added_time_ids=added_time_ids.to(dtype=dtype),\n",
    "        down_block_additional_residuals= None,\n",
    "        mid_block_additional_residual = None,\n",
    "        return_dict=False,\n",
    "    )[0]\n",
    "\n",
    "    print(noise_pred.shape)\n",
    "    if noise_pred is not None:\n",
    "        del noise_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controlnet Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple, Union, Dict, Any\n",
    "\n",
    "class UNetSpatioTemporalConditionOutput(BaseOutput):\n",
    "    \"\"\"\n",
    "    The output of [`UNetSpatioTemporalConditionModel`].\n",
    "\n",
    "    Args:\n",
    "        sample (`torch.FloatTensor` of shape `(batch_size, num_frames, num_channels, height, width)`):\n",
    "            The hidden states output conditioned on `encoder_hidden_states` input. Output of last layer of model.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    sample: torch.FloatTensor = None\n",
    "\n",
    "\n",
    "class SpatioTemporalControlNetOutput(BaseOutput):\n",
    "    \"\"\"\n",
    "    The output of [`ControlNetModel`].\n",
    "\n",
    "    Args:\n",
    "        down_block_res_samples (`tuple[torch.Tensor]`):\n",
    "            A tuple of downsample activations at different resolutions for each downsampling block. Each tensor should\n",
    "            be of shape `(batch_size, channel * resolution, height //resolution, width // resolution)`. Output can be\n",
    "            used to condition the original UNet's downsampling activations.\n",
    "        mid_down_block_re_sample (`torch.Tensor`):\n",
    "            The activation of the midde block (the lowest sample resolution). Each tensor should be of shape\n",
    "            `(batch_size, channel * lowest_resolution, height // lowest_resolution, width // lowest_resolution)`.\n",
    "            Output can be used to condition the original UNet's middle block activation.\n",
    "    \"\"\"\n",
    "\n",
    "    down_block_res_samples: Tuple[torch.Tensor]\n",
    "    mid_block_res_sample: torch.Tensor\n",
    "    \n",
    "    # Add a class which prints the sizes of the tensors\n",
    "    def print_sizes(self):\n",
    "        print(f\"Down block res samples: {self.down_block_res_samples[0].shape}\")\n",
    "        print(f\"Mid block res sample: {self.mid_block_res_sample.shape}\")\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SpatioTemporalControlNet(ModelMixin, ConfigMixin):\n",
    "    \"\"\"\n",
    "    A SpatioTemporalControlNet model for conditioning on spatio-temporal data.\n",
    "    This model adapts concepts from both ControlNetModel and UNetSpatioTemporalConditionModel,\n",
    "    focusing on handling video frames over time.\n",
    "    \"\"\"\n",
    "\n",
    "    _supports_gradient_checkpointing = True\n",
    "\n",
    "    @register_to_config\n",
    "    def __init__(\n",
    "        self,\n",
    "        sample_size: Optional[int] = None,\n",
    "        in_channels: int = 8,\n",
    "        down_block_types: Tuple[str] = (\n",
    "            \"CrossAttnDownBlockSpatioTemporal\",\n",
    "            \"CrossAttnDownBlockSpatioTemporal\",\n",
    "            \"CrossAttnDownBlockSpatioTemporal\",\n",
    "            \"DownBlockSpatioTemporal\",\n",
    "        ),\n",
    "        block_out_channels: Tuple[int] = (320, 640, 1280, 1280),\n",
    "        addition_time_embed_dim: int = 256,\n",
    "        projection_class_embeddings_input_dim: int = 768,\n",
    "        layers_per_block: Union[int, Tuple[int]] = 2,\n",
    "        cross_attention_dim: Union[int, Tuple[int]] = 1024,\n",
    "        transformer_layers_per_block: Union[int, Tuple[int], Tuple[Tuple]] = 1,\n",
    "        num_attention_heads: Union[int, Tuple[int]] = (5, 10, 10, 20),\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.sample_size = sample_size\n",
    "\n",
    "\n",
    "        # input\n",
    "        self.conv_in = nn.Conv2d(\n",
    "            in_channels,\n",
    "            block_out_channels[0],\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "        )\n",
    "\n",
    "        # time\n",
    "        time_embed_dim = block_out_channels[0] * 4\n",
    "\n",
    "        self.time_proj = Timesteps(block_out_channels[0], True, downscale_freq_shift=0)\n",
    "        timestep_input_dim = block_out_channels[0]\n",
    "\n",
    "        self.time_embedding = TimestepEmbedding(timestep_input_dim, time_embed_dim)\n",
    "\n",
    "        self.add_time_proj = Timesteps(addition_time_embed_dim, True, downscale_freq_shift=0)\n",
    "        self.add_embedding = TimestepEmbedding(projection_class_embeddings_input_dim, time_embed_dim)\n",
    "\n",
    "\n",
    "        output_channel = block_out_channels[0]\n",
    "        \n",
    "        self.controlnet_down_blocks = None\n",
    "        self.down_blocks = nn.ModuleList([])\n",
    "\n",
    "\n",
    "        \n",
    "        if isinstance(num_attention_heads, int):\n",
    "            num_attention_heads = (num_attention_heads,) * len(down_block_types)\n",
    "\n",
    "        if isinstance(cross_attention_dim, int):\n",
    "            cross_attention_dim = (cross_attention_dim,) * len(down_block_types)\n",
    "\n",
    "        if isinstance(layers_per_block, int):\n",
    "            layers_per_block = [layers_per_block] * len(down_block_types)\n",
    "\n",
    "        if isinstance(transformer_layers_per_block, int):\n",
    "            transformer_layers_per_block = [transformer_layers_per_block] * len(down_block_types)\n",
    "\n",
    "        blocks_time_embed_dim = time_embed_dim\n",
    "\n",
    "        # Initialize the connection between the down blocks and the unet\n",
    "        output_channel = block_out_channels[0]\n",
    "\n",
    "        # controlnet_block = nn.Conv2d(output_channel, output_channel, kernel_size=1)\n",
    "        # controlnet_block = zero_module(controlnet_block)\n",
    "        # self.controlnet_down_blocks.append(controlnet_block)\n",
    "\n",
    "        # down\n",
    "        output_channel = block_out_channels[0]\n",
    "        for i, down_block_type in enumerate(down_block_types):\n",
    "            input_channel = output_channel\n",
    "            output_channel = block_out_channels[i]\n",
    "            is_final_block = i == len(block_out_channels) - 1\n",
    "\n",
    "            down_block = get_down_block(\n",
    "                in_channels=input_channel,\n",
    "                out_channels=output_channel,\n",
    "                temb_channels=blocks_time_embed_dim,\n",
    "                num_layers=layers_per_block[i],\n",
    "                transformer_layers_per_block=transformer_layers_per_block[i],\n",
    "                add_downsample= not is_final_block,\n",
    "                resnet_eps=1e-5,\n",
    "                down_block_type=down_block_type,\n",
    "                cross_attention_dim=cross_attention_dim[i],\n",
    "                num_attention_heads=num_attention_heads[i],\n",
    "                resnet_act_fn=\"silu\",\n",
    "            )\n",
    "            self.down_blocks.append(down_block)\n",
    "\n",
    "            # for _ in range(layers_per_block[i]):\n",
    "            #     controlnet_block = nn.Conv2d(output_channel, output_channel, kernel_size=1)\n",
    "            #     controlnet_block = zero_module(controlnet_block)\n",
    "            #     self.controlnet_down_blocks.append(controlnet_block)\n",
    "\n",
    "            # if not is_final_block:\n",
    "            #     controlnet_block = nn.Conv2d(output_channel, output_channel, kernel_size=1)\n",
    "            #     controlnet_block = zero_module(controlnet_block)\n",
    "            #     self.controlnet_down_blocks.append(controlnet_block)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # hardcoded_controlnet_block_dims = [320,320, 640,640, 1280, 1280, 1280,1280,1280]\n",
    "        # for index, controlnet_block_dim in enumerate(hardcoded_controlnet_block_dims):\n",
    "        #     controlnet_block = nn.Conv2d(controlnet_block_dim, controlnet_block_dim, kernel_size=1)\n",
    "        #     controlnet_block = zero_module(controlnet_block)\n",
    "        #     self.controlnet_down_blocks.append(controlnet_block)\n",
    "\n",
    "\n",
    "        # Connections for the mid block\n",
    "        mid_block_channel = block_out_channels[-1]\n",
    "\n",
    "        controlnet_block = nn.Conv2d(mid_block_channel, mid_block_channel, kernel_size=1)\n",
    "        controlnet_block = zero_module(controlnet_block)\n",
    "        self.controlnet_mid_block = controlnet_block\n",
    "\n",
    "\n",
    "        # mid\n",
    "        self.mid_block = UNetMidBlockSpatioTemporal(\n",
    "            block_out_channels[-1],\n",
    "            temb_channels=blocks_time_embed_dim,\n",
    "            transformer_layers_per_block=transformer_layers_per_block[-1],\n",
    "            cross_attention_dim=cross_attention_dim[-1],\n",
    "            num_attention_heads=num_attention_heads[-1],\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        sample: torch.FloatTensor,\n",
    "        timestep: Union[torch.Tensor, float, int],\n",
    "        encoder_hidden_states: torch.Tensor,\n",
    "        added_time_ids: torch.Tensor,\n",
    "        return_dict: bool = True,\n",
    "    ) -> Union[UNetSpatioTemporalConditionOutput, Tuple]:\n",
    "        r\"\"\"\n",
    "        The [`UNetSpatioTemporalConditionModel`] forward method.\n",
    "\n",
    "        Args:\n",
    "            sample (`torch.FloatTensor`):\n",
    "                The noisy input tensor with the following shape `(batch, num_frames, channel, height, width)`.\n",
    "            timestep (`torch.FloatTensor` or `float` or `int`): The number of timesteps to denoise an input.\n",
    "            encoder_hidden_states (`torch.FloatTensor`):\n",
    "                The encoder hidden states with shape `(batch, sequence_length, cross_attention_dim)`.\n",
    "            added_time_ids: (`torch.FloatTensor`):\n",
    "                The additional time ids with shape `(batch, num_additional_ids)`. These are encoded with sinusoidal\n",
    "                embeddings and added to the time embeddings.\n",
    "            return_dict (`bool`, *optional*, defaults to `True`):\n",
    "                Whether or not to return a [`~models.unet_slatio_temporal.UNetSpatioTemporalConditionOutput`] instead of a plain\n",
    "                tuple.\n",
    "        Returns:\n",
    "            [`~models.unet_slatio_temporal.UNetSpatioTemporalConditionOutput`] or `tuple`:\n",
    "                If `return_dict` is True, an [`~models.unet_slatio_temporal.UNetSpatioTemporalConditionOutput`] is returned, otherwise\n",
    "                a `tuple` is returned where the first element is the sample tensor.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # 1. time\n",
    "        timesteps = timestep\n",
    "        if not torch.is_tensor(timesteps):\n",
    "            # TODO: this requires sync between CPU and GPU. So try to pass timesteps as tensors if you can\n",
    "            # This would be a good case for the `match` statement (Python 3.10+)\n",
    "            is_mps = sample.device.type == \"mps\"\n",
    "            if isinstance(timestep, float):\n",
    "                dtype = torch.float32 if is_mps else torch.float64\n",
    "            else:\n",
    "                dtype = torch.int32 if is_mps else torch.int64\n",
    "            timesteps = torch.tensor([timesteps], dtype=dtype, device=sample.device)\n",
    "        elif len(timesteps.shape) == 0:\n",
    "            timesteps = timesteps[None].to(sample.device)\n",
    "\n",
    "        # broadcast to batch dimension in a way that's compatible with ONNX/Core ML\n",
    "        batch_size, num_frames = sample.shape[:2]\n",
    "        timesteps = timesteps.expand(batch_size)\n",
    "\n",
    "        t_emb = self.time_proj(timesteps)\n",
    "\n",
    "        # `Timesteps` does not contain any weights and will always return f32 tensors\n",
    "        # but time_embedding might actually be running in fp16. so we need to cast here.\n",
    "        # there might be better ways to encapsulate this.\n",
    "        t_emb = t_emb.to(dtype=sample.dtype)\n",
    "\n",
    "        emb = self.time_embedding(t_emb)\n",
    "\n",
    "        time_embeds = self.add_time_proj(added_time_ids.flatten())\n",
    "        time_embeds = time_embeds.reshape((batch_size, -1))\n",
    "        time_embeds = time_embeds.to(emb.dtype)\n",
    "        aug_emb = self.add_embedding(time_embeds)\n",
    "        emb = emb + aug_emb\n",
    "\n",
    "        # Flatten the batch and frames dimensions\n",
    "        # sample: [batch, frames, channels, height, width] -> [batch * frames, channels, height, width]\n",
    "        sample = sample.flatten(0, 1)\n",
    "        # Repeat the embeddings num_video_frames times\n",
    "        # emb: [batch, channels] -> [batch * frames, channels]\n",
    "        emb = emb.repeat_interleave(num_frames, dim=0).to(sample.device)\n",
    "        # encoder_hidden_states: [batch, 1, channels] -> [batch * frames, 1, channels]\n",
    "        # Let encoder_hidden_states be just zeros in the correct format\n",
    "        # encoder_hidden_states = encoder_hidden_states.repeat_interleave(num_frames, dim=0)\n",
    "        shape_encoder_hidden_states = (batch_size * num_frames, 1, 1024)\n",
    "        encoder_hidden_states = torch.zeros(shape_encoder_hidden_states, device=sample.device).repeat_interleave(num_frames, dim=0).to(dtype=sample.dtype)\n",
    "        print(f\"Shape of encoder hidden states: {encoder_hidden_states.shape}\")\n",
    "        \n",
    "\n",
    "        # 2. pre-process\n",
    "        sample = self.conv_in(sample)\n",
    "\n",
    "        # print the device where the sample is\n",
    "        print(f\"Sample is on: {sample.device}\")\n",
    "\n",
    "\n",
    "        # Print the shape of the encoder_hidden_states\n",
    "        print(f\"Encoder hidden states shape: {encoder_hidden_states.shape}\")\n",
    "\n",
    "        image_only_indicator = torch.zeros(batch_size, num_frames, dtype=sample.dtype, device=sample.device)\n",
    "\n",
    "        down_block_res_samples = (sample,)\n",
    "        for downsample_block in self.down_blocks:\n",
    "            if hasattr(downsample_block, \"has_cross_attention\") and downsample_block.has_cross_attention:\n",
    "                sample, res_samples = downsample_block(\n",
    "                    hidden_states=sample,\n",
    "                    temb=emb,\n",
    "                    encoder_hidden_states=encoder_hidden_states,\n",
    "                    image_only_indicator=image_only_indicator,\n",
    "                )\n",
    "            else:\n",
    "                sample, res_samples = downsample_block(\n",
    "                    hidden_states=sample,\n",
    "                    temb=emb,\n",
    "                    image_only_indicator=image_only_indicator,\n",
    "                )\n",
    "            # Print the shapes of the res_samples\n",
    "            down_block_res_samples += res_samples\n",
    "            print(f\"Res samples shape control: {res_samples[0].shape}\")\n",
    "\n",
    "        # Print the length of the down_block_res_samples\n",
    "        print(f\"Length of down_block_res_samples control: {len(down_block_res_samples)}\")\n",
    "\n",
    "        # 4. mid\n",
    "        sample = self.mid_block(\n",
    "            hidden_states=sample,\n",
    "        temb=emb,\n",
    "            encoder_hidden_states=encoder_hidden_states,\n",
    "            image_only_indicator=image_only_indicator,\n",
    "        )\n",
    "\n",
    "        \n",
    "        # 5. Control net blocks\n",
    "\n",
    "        # initialize the controlnet_down_block_res_samples of it is on embpy nn.ModuleList\n",
    "        if self.controlnet_down_blocks is None:\n",
    "            self.controlnet_down_blocks = nn.ModuleList([])\n",
    "\n",
    "\n",
    "            for down_block_res_sample in down_block_res_samples:\n",
    "                # Determine the current number of channels in the tensor\n",
    "                current_channels = down_block_res_sample.size(1)\n",
    "                \n",
    "                # Dynamically create a zero convolution block for the current tensor\n",
    "                controlnet_block = nn.Conv2d(current_channels, current_channels, kernel_size=1)\n",
    "                controlnet_block = zero_module(controlnet_block).to(down_block_res_sample.device, dtype=sample.dtype)\n",
    "            \n",
    "                \n",
    "                # Store the processed sample for further use\n",
    "                self.controlnet_down_blocks.append(controlnet_block)\n",
    "    \n",
    "\n",
    "        controlnet_down_block_res_samples = ()\n",
    "\n",
    "        for index , (down_block_res_sample, controlnet_block) in enumerate(zip(down_block_res_samples, self.controlnet_down_blocks)):\n",
    "\n",
    "            # print to the debug console the device where the down_block_res_sample is\n",
    "            try:\n",
    "                # print the size of the down_block_res_sample\n",
    "                print(f\"Down block res sample shape before the conversion: {down_block_res_sample.shape}\")\n",
    "                down_block_res_sample = controlnet_block(down_block_res_sample)\n",
    "                controlnet_down_block_res_samples = controlnet_down_block_res_samples + (down_block_res_sample,)\n",
    "            except Exception as e:\n",
    "                # Print the error in conjecuntion with the index\n",
    "                print(f\"Error at index {index}: {e}\")\n",
    "\n",
    "        down_block_res_samples = controlnet_down_block_res_samples\n",
    "\n",
    "        mid_block_res_sample = self.controlnet_mid_block(sample)\n",
    "\n",
    "        down_block_res_samples = [sample for sample in down_block_res_samples]\n",
    "        mid_block_res_sample = mid_block_res_sample\n",
    "\n",
    "        if not return_dict:\n",
    "            return (down_block_res_samples, mid_block_res_sample)\n",
    "\n",
    "        return SpatioTemporalControlNetOutput(\n",
    "            down_block_res_samples=down_block_res_samples, mid_block_res_sample=mid_block_res_sample\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def from_unet(\n",
    "        cls,\n",
    "        unet: UNetSpatioTemporalConditionModel,\n",
    "        load_weights_from_unet: bool = True,\n",
    "    ):\n",
    "        \n",
    "        addition_time_embed_dim = (\n",
    "            unet.config.addition_time_embed_dim if \"addition_time_embed_dim\" in unet.config else None\n",
    "        )\n",
    "\n",
    "        controlnet = cls(\n",
    "            in_channels=unet.config.in_channels,\n",
    "            down_block_types=unet.config.down_block_types,\n",
    "            block_out_channels=unet.config.block_out_channels,  # What are block out channels\n",
    "            addition_time_embed_dim=addition_time_embed_dim,\n",
    "            projection_class_embeddings_input_dim=unet.config.projection_class_embeddings_input_dim,\n",
    "            layers_per_block=unet.config.layers_per_block,\n",
    "            cross_attention_dim=unet.config.cross_attention_dim,\n",
    "            transformer_layers_per_block=unet.config.transformer_layers_per_block,\n",
    "            num_attention_heads=unet.config.num_attention_heads,\n",
    "        )\n",
    "\n",
    "        if load_weights_from_unet:\n",
    "            controlnet.conv_in.load_state_dict(unet.conv_in.state_dict())\n",
    "            controlnet.time_proj.load_state_dict(unet.time_proj.state_dict())\n",
    "            controlnet.time_embedding.load_state_dict(unet.time_embedding.state_dict())\n",
    "\n",
    "            controlnet.down_blocks.load_state_dict(unet.down_blocks.state_dict())\n",
    "            controlnet.mid_block.load_state_dict(unet.mid_block.state_dict())\n",
    "\n",
    "        return controlnet\n",
    "\n",
    "\n",
    "def zero_module(module):\n",
    "    for p in module.parameters():\n",
    "        nn.init.zeros_(p)\n",
    "    return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpatioTemporalControlNet(\n",
       "  (conv_in): Conv2d(8, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (time_proj): Timesteps()\n",
       "  (time_embedding): TimestepEmbedding(\n",
       "    (linear_1): LoRACompatibleLinear(in_features=320, out_features=1280, bias=True)\n",
       "    (act): SiLU()\n",
       "    (linear_2): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "  )\n",
       "  (add_time_proj): Timesteps()\n",
       "  (add_embedding): TimestepEmbedding(\n",
       "    (linear_1): LoRACompatibleLinear(in_features=768, out_features=1280, bias=True)\n",
       "    (act): SiLU()\n",
       "    (linear_2): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "  )\n",
       "  (down_blocks): ModuleList(\n",
       "    (0): CrossAttnDownBlockSpatioTemporal(\n",
       "      (attentions): ModuleList(\n",
       "        (0-1): 2 x TransformerSpatioTemporalModel(\n",
       "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "          (proj_in): Linear(in_features=320, out_features=320, bias=True)\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=1024, out_features=320, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=1024, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (temporal_transformer_blocks): ModuleList(\n",
       "            (0): TemporalBasicTransformerBlock(\n",
       "              (norm_in): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff_in): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=1024, out_features=320, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=1024, out_features=320, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=320, out_features=320, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=320, out_features=2560, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (time_pos_embed): TimestepEmbedding(\n",
       "            (linear_1): LoRACompatibleLinear(in_features=320, out_features=1280, bias=True)\n",
       "            (act): SiLU()\n",
       "            (linear_2): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "          )\n",
       "          (time_proj): Timesteps()\n",
       "          (time_mixer): AlphaBlender()\n",
       "          (proj_out): Linear(in_features=320, out_features=320, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x SpatioTemporalResBlock(\n",
       "          (spatial_res_block): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "            (conv1): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "            (norm2): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "          (temporal_res_block): TemporalResnetBlock(\n",
       "            (norm1): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "            (conv1): Conv3d(320, 320, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            (norm2): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv3d(320, 320, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): CrossAttnDownBlockSpatioTemporal(\n",
       "      (attentions): ModuleList(\n",
       "        (0-1): 2 x TransformerSpatioTemporalModel(\n",
       "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "          (proj_in): Linear(in_features=640, out_features=640, bias=True)\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (temporal_transformer_blocks): ModuleList(\n",
       "            (0): TemporalBasicTransformerBlock(\n",
       "              (norm_in): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff_in): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=1024, out_features=640, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=640, out_features=5120, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=2560, out_features=640, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (time_pos_embed): TimestepEmbedding(\n",
       "            (linear_1): LoRACompatibleLinear(in_features=640, out_features=2560, bias=True)\n",
       "            (act): SiLU()\n",
       "            (linear_2): LoRACompatibleLinear(in_features=2560, out_features=640, bias=True)\n",
       "          )\n",
       "          (time_proj): Timesteps()\n",
       "          (time_mixer): AlphaBlender()\n",
       "          (proj_out): Linear(in_features=640, out_features=640, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): SpatioTemporalResBlock(\n",
       "          (spatial_res_block): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "            (conv1): LoRACompatibleConv(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n",
       "            (norm2): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (temporal_res_block): TemporalResnetBlock(\n",
       "            (norm1): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (conv1): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            (norm2): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "        (1): SpatioTemporalResBlock(\n",
       "          (spatial_res_block): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (conv1): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n",
       "            (norm2): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "          (temporal_res_block): TemporalResnetBlock(\n",
       "            (norm1): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (conv1): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
       "            (norm2): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv3d(640, 640, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): CrossAttnDownBlockSpatioTemporal(\n",
       "      (attentions): ModuleList(\n",
       "        (0-1): 2 x TransformerSpatioTemporalModel(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (temporal_transformer_blocks): ModuleList(\n",
       "            (0): TemporalBasicTransformerBlock(\n",
       "              (norm_in): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff_in): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=1024, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (time_pos_embed): TimestepEmbedding(\n",
       "            (linear_1): LoRACompatibleLinear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): SiLU()\n",
       "            (linear_2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n",
       "          )\n",
       "          (time_proj): Timesteps()\n",
       "          (time_mixer): AlphaBlender()\n",
       "          (proj_out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): SpatioTemporalResBlock(\n",
       "          (spatial_res_block): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (conv1): LoRACompatibleConv(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "            (norm2): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (temporal_res_block): TemporalResnetBlock(\n",
       "            (norm1): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (conv1): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (norm2): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "        (1): SpatioTemporalResBlock(\n",
       "          (spatial_res_block): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (conv1): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "            (norm2): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "          (temporal_res_block): TemporalResnetBlock(\n",
       "            (norm1): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (conv1): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (norm2): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): DownBlockSpatioTemporal(\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x SpatioTemporalResBlock(\n",
       "          (spatial_res_block): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "            (conv1): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "            (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "          (temporal_res_block): TemporalResnetBlock(\n",
       "            (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "            (conv1): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "          (time_mixer): AlphaBlender()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (controlnet_mid_block): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (mid_block): UNetMidBlockSpatioTemporal(\n",
       "    (attentions): ModuleList(\n",
       "      (0): TransformerSpatioTemporalModel(\n",
       "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "        (proj_in): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn1): Attention(\n",
       "              (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_v): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_out): ModuleList(\n",
       "                (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn2): Attention(\n",
       "              (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): LoRACompatibleLinear(in_features=1024, out_features=1280, bias=False)\n",
       "              (to_v): LoRACompatibleLinear(in_features=1024, out_features=1280, bias=False)\n",
       "              (to_out): ModuleList(\n",
       "                (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (ff): FeedForward(\n",
       "              (net): ModuleList(\n",
       "                (0): GEGLU(\n",
       "                  (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (temporal_transformer_blocks): ModuleList(\n",
       "          (0): TemporalBasicTransformerBlock(\n",
       "            (norm_in): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (ff_in): FeedForward(\n",
       "              (net): ModuleList(\n",
       "                (0): GEGLU(\n",
       "                  (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn1): Attention(\n",
       "              (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_v): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_out): ModuleList(\n",
       "                (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn2): Attention(\n",
       "              (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): LoRACompatibleLinear(in_features=1024, out_features=1280, bias=False)\n",
       "              (to_v): LoRACompatibleLinear(in_features=1024, out_features=1280, bias=False)\n",
       "              (to_out): ModuleList(\n",
       "                (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (ff): FeedForward(\n",
       "              (net): ModuleList(\n",
       "                (0): GEGLU(\n",
       "                  (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (time_pos_embed): TimestepEmbedding(\n",
       "          (linear_1): LoRACompatibleLinear(in_features=1280, out_features=5120, bias=True)\n",
       "          (act): SiLU()\n",
       "          (linear_2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "        (time_proj): Timesteps()\n",
       "        (time_mixer): AlphaBlender()\n",
       "        (proj_out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (resnets): ModuleList(\n",
       "      (0-1): 2 x SpatioTemporalResBlock(\n",
       "        (spatial_res_block): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (conv1): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "        (temporal_res_block): TemporalResnetBlock(\n",
       "          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (conv1): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv3d(1280, 1280, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "        (time_mixer): AlphaBlender()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the contrl net from my_net\n",
    "control_net = SpatioTemporalControlNet.from_unet(my_net)\n",
    "control_net = control_net.half()\n",
    "control_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent model input is on: cuda:0\n",
      "Hidden image embeddings are on: cuda:0\n",
      "Added time IDs are on: cuda:0\n",
      "Time is on: cpu\n",
      "Time is on: cuda:0\n",
      "Shape of encoder hidden states: torch.Size([2, 1, 1024])\n",
      "Sample is on: cuda:0\n",
      "Encoder hidden states shape: torch.Size([2, 1, 1024])\n",
      "Res samples shape control: torch.Size([2, 320, 64, 64])\n",
      "Res samples shape control: torch.Size([2, 640, 32, 32])\n",
      "Res samples shape control: torch.Size([2, 1280, 16, 16])\n",
      "Res samples shape control: torch.Size([2, 1280, 8, 8])\n",
      "Length of down_block_res_samples control: 12\n",
      "Down block res sample shape before the conversion: torch.Size([2, 320, 64, 64])\n",
      "Down block res sample shape before the conversion: torch.Size([2, 320, 64, 64])\n",
      "Down block res sample shape before the conversion: torch.Size([2, 320, 64, 64])\n",
      "Down block res sample shape before the conversion: torch.Size([2, 320, 32, 32])\n",
      "Down block res sample shape before the conversion: torch.Size([2, 640, 32, 32])\n",
      "Down block res sample shape before the conversion: torch.Size([2, 640, 32, 32])\n",
      "Down block res sample shape before the conversion: torch.Size([2, 640, 16, 16])\n",
      "Down block res sample shape before the conversion: torch.Size([2, 1280, 16, 16])\n",
      "Down block res sample shape before the conversion: torch.Size([2, 1280, 16, 16])\n",
      "Down block res sample shape before the conversion: torch.Size([2, 1280, 8, 8])\n",
      "Down block res sample shape before the conversion: torch.Size([2, 1280, 8, 8])\n",
      "Down block res sample shape before the conversion: torch.Size([2, 1280, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    time =  torch.tensor(1).to(dtype=dtype)\n",
    "\n",
    "    # print on which device the input is\n",
    "    print(f\"Latent model input is on: {latent_model_input.device}\")\n",
    "    print(f\"Hidden image embeddings are on: {hidden_image_embeddings.device}\")\n",
    "    print(f\"Added time IDs are on: {added_time_ids.device}\")\n",
    "    print(f\"Time is on: {time.device}\")\n",
    "\n",
    "    # move time to divice\n",
    "    time = time.to(device)\n",
    "    print(f\"Time is on: {time.device}\")\n",
    "           \n",
    "    noise_pred = control_net.forward(\n",
    "        latent_model_input.to(dtype=dtype),\n",
    "        time,\n",
    "        encoder_hidden_states=hidden_image_embeddings.to(dtype=dtype),\n",
    "        added_time_ids=added_time_ids.to(dtype=dtype),\n",
    "        return_dict=True,\n",
    "    )    \n",
    "    \n",
    "\n",
    "    # Print the sizes of the tensors\n",
    " \n",
    "    if noise_pred is not None:\n",
    "        del noise_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of encoder hidden states: torch.Size([2, 1, 1024])\n",
      "Sample is on: cuda:0\n",
      "Encoder hidden states shape: torch.Size([2, 1, 1024])\n",
      "Res samples shape control: torch.Size([2, 320, 64, 64])\n",
      "Res samples shape control: torch.Size([2, 640, 32, 32])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res samples shape control: torch.Size([2, 1280, 16, 16])\n",
      "Res samples shape control: torch.Size([2, 1280, 8, 8])\n",
      "Length of down_block_res_samples control: 12\n",
      "Down block res sample shape before the conversion: torch.Size([2, 320, 64, 64])\n",
      "Down block res sample shape before the conversion: torch.Size([2, 320, 64, 64])\n",
      "Down block res sample shape before the conversion: torch.Size([2, 320, 64, 64])\n",
      "Down block res sample shape before the conversion: torch.Size([2, 320, 32, 32])\n",
      "Down block res sample shape before the conversion: torch.Size([2, 640, 32, 32])\n",
      "Down block res sample shape before the conversion: torch.Size([2, 640, 32, 32])\n",
      "Down block res sample shape before the conversion: torch.Size([2, 640, 16, 16])\n",
      "Down block res sample shape before the conversion: torch.Size([2, 1280, 16, 16])\n",
      "Down block res sample shape before the conversion: torch.Size([2, 1280, 16, 16])\n",
      "Down block res sample shape before the conversion: torch.Size([2, 1280, 8, 8])\n",
      "Down block res sample shape before the conversion: torch.Size([2, 1280, 8, 8])\n",
      "Down block res sample shape before the conversion: torch.Size([2, 1280, 8, 8])\n",
      "Length of down_block_res_samples afterprocesssing: 12\n",
      "This is the batch size 2\n",
      "Res samples shape unet: torch.Size([2, 320, 64, 64])\n",
      "Res samples shape unet: torch.Size([2, 640, 32, 32])\n",
      "Res samples shape unet: torch.Size([2, 1280, 16, 16])\n",
      "Res samples shape unet: torch.Size([2, 1280, 8, 8])\n",
      "Down block res samples shape uuuuuuuu: torch.Size([2, 320, 64, 64])\n",
      "Down block res samples shape uuuuuuuu: torch.Size([2, 320, 64, 64])\n",
      "Down block res samples shape uuuuuuuu: torch.Size([2, 320, 64, 64])\n",
      "Down block res samples shape uuuuuuuu: torch.Size([2, 320, 32, 32])\n",
      "Down block res samples shape uuuuuuuu: torch.Size([2, 640, 32, 32])\n",
      "Down block res samples shape uuuuuuuu: torch.Size([2, 640, 32, 32])\n",
      "Down block res samples shape uuuuuuuu: torch.Size([2, 640, 16, 16])\n",
      "Down block res samples shape uuuuuuuu: torch.Size([2, 1280, 16, 16])\n",
      "Down block res samples shape uuuuuuuu: torch.Size([2, 1280, 16, 16])\n",
      "Down block res samples shape uuuuuuuu: torch.Size([2, 1280, 8, 8])\n",
      "Down block res samples shape uuuuuuuu: torch.Size([2, 1280, 8, 8])\n",
      "Down block res samples shape uuuuuuuu: torch.Size([2, 1280, 8, 8])\n",
      "This is the iteration 0\n",
      "This is the iteration 1\n",
      "This is the iteration 2\n",
      "This is the iteration 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    (down_block_res_samples, mid_block_res_samples) = control_net.forward(\n",
    "        latent_model_input.to(dtype=dtype),\n",
    "        time,\n",
    "        encoder_hidden_states=hidden_image_embeddings.to(dtype=dtype),\n",
    "        added_time_ids=added_time_ids.to(dtype=dtype),\n",
    "        return_dict=False,\n",
    "    )\n",
    "\n",
    "    # reverse the down_block_res_samples tuple\n",
    "    # down_block_res_samples = down_block_res_samples[::-1]\n",
    "\n",
    "    print(f\"Length of down_block_res_samples afterprocesssing: {len(down_block_res_samples)}\")\n",
    "\n",
    "\n",
    "    noise_pred = my_net.forward(\n",
    "        latent_model_input.to(dtype=dtype),\n",
    "        torch.tensor(1).to(dtype=dtype, device=device),\n",
    "        encoder_hidden_states=hidden_image_embeddings.to(dtype=dtype),\n",
    "        # Maybe I need to reverse the order of the tensors\n",
    "        down_block_additional_residuals= down_block_res_samples,\n",
    "        mid_block_additional_residual = mid_block_res_samples,\n",
    "        added_time_ids=added_time_ids.to(dtype=dtype),\n",
    "        return_dict=False,\n",
    "    )[0]\n",
    "\n",
    "    # Print the sizes of the tensors\n",
    "    if noise_pred is not None:\n",
    "        del noise_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from diffusers.pipelines.stable_video_diffusion.pipeline_stable_video_diffusion_with_controlnet import StableVideoDiffusionPipelineWithControlNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_with_controlnet = StableVideoDiffusionPipelineWithControlNet(\n",
    "    vae = pipe.vae,\n",
    "    image_encoder = pipe.image_encoder,\n",
    "    unet=my_net,\n",
    "    scheduler=pipe.scheduler,\n",
    "    feature_extractor=pipe.feature_extractor,\n",
    "    controlnet=control_net\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pipe_with_controlnet.enable_model_cpu_offload()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edit_diffusers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
